#!/usr/bin/env python3
"""
Day 8 - è¶…å‚æ•°è°ƒä¼˜PPOè®­ç»ƒè„šæœ¬
ä½¿ç”¨ä¼˜åŒ–çš„è¶…å‚æ•°é…ç½®è¿›è¡Œè®­ç»ƒ
"""

import os
import sys
import argparse
from datetime import datetime
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from stable_baselines3 import PPO
from stable_baselines3.common.vec_env import DummyVecEnv
from stable_baselines3.common.callbacks import EvalCallback, CheckpointCallback
from simulator.bike_env import BikeRebalancingEnv
from simulator.utils import load_config
import torch.nn as nn


def parse_args():
    parser = argparse.ArgumentParser(description='è¶…å‚æ•°è°ƒä¼˜PPOè®­ç»ƒ')
    parser.add_argument('--timesteps', type=int, default=150000,
                       help='æ€»è®­ç»ƒæ­¥æ•°ï¼ˆé»˜è®¤150kï¼Œæ¯”Day 7çš„100kæ›´å¤šï¼‰')
    parser.add_argument('--lr', type=float, default=1e-4,
                       help='å­¦ä¹ ç‡ï¼ˆé™ä½ä»¥æé«˜ç¨³å®šæ€§ï¼‰')
    parser.add_argument('--n-steps', type=int, default=4096,
                       help='æ¯æ¬¡æ›´æ–°çš„æ­¥æ•°ï¼ˆå¢åŠ ä»¥è·å¾—æ›´å¤šç»éªŒï¼‰')
    parser.add_argument('--batch-size', type=int, default=128,
                       help='æ‰¹å¤§å°ï¼ˆå¢åŠ ä»¥æé«˜æ¢¯åº¦ä¼°è®¡è´¨é‡ï¼‰')
    parser.add_argument('--n-epochs', type=int, default=10,
                       help='æ¯æ¬¡æ›´æ–°çš„epochæ•°')
    parser.add_argument('--gamma', type=float, default=0.99,
                       help='æŠ˜æ‰£å› å­')
    parser.add_argument('--gae-lambda', type=float, default=0.95,
                       help='GAE lambda')
    parser.add_argument('--clip-range', type=float, default=0.2,
                       help='PPO clip range')
    parser.add_argument('--ent-coef', type=float, default=0.01,
                       help='ç†µç³»æ•°ï¼ˆå¢åŠ æ¢ç´¢æ€§ï¼‰')
    parser.add_argument('--vf-coef', type=float, default=0.5,
                       help='ä»·å€¼å‡½æ•°ç³»æ•°')
    parser.add_argument('--max-grad-norm', type=float, default=0.5,
                       help='æ¢¯åº¦è£å‰ª')
    parser.add_argument('--net-arch', type=str, default='256,256',
                       help='ç½‘ç»œç»“æ„ï¼ˆé€—å·åˆ†éš”ï¼Œå¦‚: 256,256,128ï¼‰')
    parser.add_argument('--quick-test', action='store_true',
                       help='è®­ç»ƒåè¿›è¡Œå¿«é€Ÿæµ‹è¯•')
    parser.add_argument('--seed', type=int, default=42,
                       help='éšæœºç§å­')
    return parser.parse_args()


def parse_net_arch(arch_str):
    """è§£æç½‘ç»œç»“æ„å­—ç¬¦ä¸²"""
    return [int(x) for x in arch_str.split(',')]


def quick_test(model, config, episodes=3):
    """å¿«é€Ÿæµ‹è¯•è®­ç»ƒçš„æ¨¡å‹"""
    print("\n" + "="*70)
    print("å¿«é€Ÿæµ‹è¯•")
    print("="*70 + "\n")
    
    test_env = BikeRebalancingEnv(config_dict=config, scenario='default')
    
    results = []
    for ep in range(episodes):
        obs, _ = test_env.reset()
        done = False
        episode_revenue = 0
        episode_cost = 0
        episode_served = 0
        episode_demand = 0
        
        while not done:
            action, _ = model.predict(obs, deterministic=True)
            obs, reward, done, truncated, info = test_env.step(action)
            
            episode_revenue += info.get('revenue', 0)
            episode_cost += info.get('rebalance_cost', 0)
            episode_served += info.get('total_served', 0)
            episode_demand += info.get('total_demand', 0)
            
            if done or truncated:
                break
        
        service_rate = episode_served / max(episode_demand, 1)
        net_profit = episode_revenue - episode_cost
        
        results.append({
            'service_rate': service_rate,
            'net_profit': net_profit,
            'cost': episode_cost
        })
        
        print(f"  Episode {ep+1}/{episodes}: "
              f"æœåŠ¡ç‡={service_rate*100:.1f}%, "
              f"å‡€åˆ©æ¶¦=${net_profit:.0f}, "
              f"æˆæœ¬=${episode_cost:.0f}")
    
    import numpy as np
    print(f"\nå¹³å‡è¡¨ç°:")
    print(f"  æœåŠ¡ç‡: {np.mean([r['service_rate'] for r in results])*100:.2f}%")
    print(f"  å‡€åˆ©æ¶¦: ${np.mean([r['net_profit'] for r in results]):.2f}")
    print(f"  è°ƒåº¦æˆæœ¬: ${np.mean([r['cost'] for r in results]):.2f}")
    print()


def main():
    args = parse_args()
    
    print("="*70)
    print("Day 8 - è¶…å‚æ•°è°ƒä¼˜PPOè®­ç»ƒ")
    print("="*70)
    print()
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = Path("results/ppo_tuned")
    models_dir = output_dir / "models"
    logs_dir = output_dir / "logs"
    
    for d in [output_dir, models_dir, logs_dir]:
        d.mkdir(parents=True, exist_ok=True)
    
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir.absolute()}")
    print()
    
    # åŠ è½½é…ç½®
    print("ğŸ“„ åŠ è½½é…ç½®...")
    config = load_config()
    print("âœ… é…ç½®åŠ è½½æˆåŠŸ")
    print()
    
    # æ˜¾ç¤ºè®­ç»ƒé…ç½®
    net_arch = parse_net_arch(args.net_arch)
    
    print("="*70)
    print("è®­ç»ƒé…ç½®")
    print("="*70)
    print()
    print("ğŸ¯ è¶…å‚æ•°ä¼˜åŒ–é‡ç‚¹:")
    print("  - æ›´ä½å­¦ä¹ ç‡ â†’ æ›´ç¨³å®šè®­ç»ƒ")
    print("  - æ›´å¤§batch â†’ æ›´å‡†ç¡®æ¢¯åº¦")
    print("  - æ›´å¤šé‡‡æ ·æ­¥ â†’ æ›´å¤šç»éªŒ")
    print("  - æ›´é•¿è®­ç»ƒ â†’ æ›´å……åˆ†å­¦ä¹ ")
    print()
    print(f"æ€»æ­¥æ•°: {args.timesteps:,} (vs Day 7: 100k)")
    print(f"å­¦ä¹ ç‡: {args.lr} (vs Day 7: 3e-4)")
    print(f"n_steps: {args.n_steps} (vs Day 7: 2048)")
    print(f"batch_size: {args.batch_size} (vs Day 7: 64)")
    print(f"n_epochs: {args.n_epochs}")
    print(f"gamma: {args.gamma}")
    print(f"gae_lambda: {args.gae_lambda}")
    print(f"clip_range: {args.clip_range}")
    print(f"ent_coef: {args.ent_coef}")
    print(f"vf_coef: {args.vf_coef}")
    print(f"max_grad_norm: {args.max_grad_norm}")
    print(f"ç½‘ç»œç»“æ„: {net_arch}")
    print(f"éšæœºç§å­: {args.seed}")
    print()
    
    # åˆ›å»ºç¯å¢ƒ
    print("="*70)
    print("åˆ›å»ºè®­ç»ƒç¯å¢ƒ")
    print("="*70)
    print()
    
    def make_env():
        return BikeRebalancingEnv(config_dict=config, scenario='default')
    
    env = DummyVecEnv([make_env])
    eval_env = DummyVecEnv([make_env])
    
    print("âœ… è®­ç»ƒç¯å¢ƒåˆ›å»ºæˆåŠŸ")
    print()
    
    # åˆ›å»ºPPOæ¨¡å‹ï¼ˆä½¿ç”¨è°ƒä¼˜çš„è¶…å‚æ•°ï¼‰
    print("="*70)
    print("åˆå§‹åŒ–PPOæ¨¡å‹")
    print("="*70)
    print()
    
    policy_kwargs = dict(
        net_arch=dict(pi=net_arch, vf=net_arch),
        activation_fn=nn.ReLU
    )
    
    model = PPO(
        "MultiInputPolicy",
        env,
        learning_rate=args.lr,
        n_steps=args.n_steps,
        batch_size=args.batch_size,
        n_epochs=args.n_epochs,
        gamma=args.gamma,
        gae_lambda=args.gae_lambda,
        clip_range=args.clip_range,
        ent_coef=args.ent_coef,
        vf_coef=args.vf_coef,
        max_grad_norm=args.max_grad_norm,
        policy_kwargs=policy_kwargs,
        verbose=1,
        tensorboard_log=str(logs_dir),
        seed=args.seed
    )
    
    print("âœ… æ¨¡å‹åˆå§‹åŒ–æˆåŠŸ")
    print(f"ğŸ“Š ç½‘ç»œç»“æ„: {net_arch}")
    print()
    
    # åˆ›å»ºå›è°ƒ
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    eval_callback = EvalCallback(
        eval_env,
        best_model_save_path=str(models_dir / "best_model"),
        log_path=str(logs_dir / "eval"),
        eval_freq=max(args.timesteps // 10, 1000),
        n_eval_episodes=5,
        deterministic=True,
        render=False,
        verbose=1
    )
    
    checkpoint_callback = CheckpointCallback(
        save_freq=max(args.timesteps // 5, 5000),
        save_path=str(models_dir / "checkpoints"),
        name_prefix=f"ppo_tuned",
        verbose=1
    )
    
    # å¼€å§‹è®­ç»ƒ
    print("="*70)
    print("å¼€å§‹è®­ç»ƒ")
    print("="*70)
    print()
    print(f"ğŸš€ å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"ğŸ“Š TensorBoard: tensorboard --logdir {logs_dir.absolute()}")
    print(f"â±ï¸  é¢„è®¡æ—¶é—´: ~{args.timesteps/1000*0.5:.0f}-{args.timesteps/1000:.0f}åˆ†é’Ÿ")
    print()
    
    model.learn(
        total_timesteps=args.timesteps,
        callback=[eval_callback, checkpoint_callback],
        progress_bar=True
    )
    
    print()
    print(f"âœ… è®­ç»ƒå®Œæˆ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print()
    
    # ä¿å­˜æœ€ç»ˆæ¨¡å‹
    final_model_path = models_dir / f"ppo_tuned_final_{timestamp}.zip"
    model.save(str(final_model_path))
    print(f"ğŸ’¾ æœ€ç»ˆæ¨¡å‹å·²ä¿å­˜: {final_model_path}")
    print()
    
    # å¿«é€Ÿæµ‹è¯•
    if args.quick_test:
        quick_test(model, config, episodes=3)
    
    print("="*70)
    print("âœ… Day 8 è¶…å‚æ•°è°ƒä¼˜è®­ç»ƒå®Œæˆï¼")
    print("="*70)
    print()
    print("ğŸ“‚ è¾“å‡ºæ–‡ä»¶:")
    print(f"  - æœ€ä½³æ¨¡å‹: {models_dir / 'best_model' / 'best_model.zip'}")
    print(f"  - æœ€ç»ˆæ¨¡å‹: {final_model_path}")
    print(f"  - è®­ç»ƒæ—¥å¿—: {logs_dir}")
    print()
    print("ğŸ¯ ä¸‹ä¸€æ­¥:")
    print("  è¿è¡Œ day8_compare_all.py å¯¹æ¯”æ‰€æœ‰æ¨¡å‹çš„æ€§èƒ½")
    print()
    
    return 0


if __name__ == "__main__":
    sys.exit(main())