#!/usr/bin/env python3
"""
Day 10 - æ•°æ®å‡†å¤‡è„šæœ¬
ä¸ºDashboardå‡†å¤‡æ‰€æœ‰éœ€è¦çš„æ•°æ®
"""

import os
import sys
import pickle
from pathlib import Path
import pandas as pd
import numpy as np
from datetime import datetime

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))


def prepare_dashboard_data():
    """å‡†å¤‡Dashboardæ‰€éœ€çš„æ‰€æœ‰æ•°æ®"""
    print("="*70)
    print("Day 10 - å‡†å¤‡Dashboardæ•°æ®")
    print("="*70)
    print()
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    dashboard_dir = project_root / "dashboard"
    data_dir = dashboard_dir / "data"
    assets_dir = dashboard_dir / "assets" / "plots"
    
    for dir_path in [data_dir, assets_dir]:
        dir_path.mkdir(parents=True, exist_ok=True)
    
    print(f"ğŸ“ Dashboardç›®å½•: {dashboard_dir.absolute()}")
    print()
    
    # 1. åŠ è½½å¯¹æ¯”æ•°æ®
    print("1ï¸âƒ£  åŠ è½½ç­–ç•¥å¯¹æ¯”æ•°æ®...")
    comparison_dir = project_root / "results" / "day8_comparison"
    comparison_files = list(comparison_dir.glob("comparison_detail_*.csv"))
    
    if not comparison_files:
        print("âŒ é”™è¯¯: æ‰¾ä¸åˆ°å¯¹æ¯”æ•°æ®ï¼Œè¯·å…ˆå®ŒæˆDay 8")
        return False
    
    latest_comparison = max(comparison_files, key=lambda p: p.stat().st_mtime)
    comparison_df = pd.read_csv(latest_comparison)
    
    # ä¿å­˜åˆ°dashboard
    comparison_df.to_csv(data_dir / "comparison.csv", index=False)
    print(f"âœ… å¯¹æ¯”æ•°æ®: {len(comparison_df)}æ¡è®°å½•")
    print()
    
    # 2. åŠ è½½å†³ç­–æ•°æ®
    print("2ï¸âƒ£  åŠ è½½å†³ç­–åˆ†ææ•°æ®...")
    analysis_dir = project_root / "results" / "day9_analysis"
    decision_files = list(analysis_dir.glob("decision_data_*.csv"))
    
    if not decision_files:
        print("âš ï¸  è­¦å‘Š: æ‰¾ä¸åˆ°å†³ç­–æ•°æ®ï¼Œå°†è·³è¿‡å†³ç­–åˆ†æé¡µé¢")
        decision_df = None
    else:
        latest_decision = max(decision_files, key=lambda p: p.stat().st_mtime)
        decision_df = pd.read_csv(latest_decision)
        decision_df.to_csv(data_dir / "decisions.csv", index=False)
        print(f"âœ… å†³ç­–æ•°æ®: {len(decision_df)}æ¡è®°å½•")
    print()
    
    # 3. ç”Ÿæˆæ±‡æ€»ç»Ÿè®¡
    print("3ï¸âƒ£  ç”Ÿæˆæ±‡æ€»ç»Ÿè®¡...")
    
    summary = {}
    
    # æŒ‰æ¨¡å‹æ±‡æ€»
    summary['by_model'] = comparison_df.groupby('model').agg({
        'service_rate': ['mean', 'std'],
        'net_profit': ['mean', 'std'],
        'total_cost': ['mean', 'std']
    }).round(2)
    
    # æŒ‰åœºæ™¯æ±‡æ€»
    summary['by_scenario'] = comparison_df.groupby('scenario').agg({
        'service_rate': 'mean',
        'net_profit': 'mean',
        'total_cost': 'mean'
    }).round(2)
    
    # æ ¸å¿ƒæŒ‡æ ‡
    day7_data = comparison_df[comparison_df['model'] == 'PPO-Day7-Original']
    day8_data = comparison_df[comparison_df['model'].str.contains('Day8')]
    baseline_data = comparison_df[comparison_df['model'] == 'Proportional-Optimized']
    
    if len(day7_data) > 0 and len(day8_data) > 0:
        day7_cost = day7_data['total_cost'].mean()
        day8_cost = day8_data['total_cost'].mean()
        day7_profit = day7_data['net_profit'].mean()
        day8_profit = day8_data['net_profit'].mean()
        
        # ROIè®¡ç®—
        day7_roi = day7_profit / day7_cost if day7_cost > 0 else 0
        day8_roi = day8_profit / day8_cost if day8_cost > 0 else 0
        
        summary['core_metrics'] = {
            'cost_reduction_pct': (1 - day8_cost / day7_cost) * 100 if day7_cost > 0 else 0,
            'cost_reduction_abs': day7_cost - day8_cost,
            'roi_day7': day7_roi,
            'roi_day8': day8_roi,
            'roi_improvement': day8_roi / day7_roi if day7_roi > 0 else 0,
            'service_rate_day8': day8_data['service_rate'].mean() * 100,
            'annual_benefit': (day7_cost - day8_cost + day8_profit - day7_profit) * 52
        }
        
        print(f"âœ… æ ¸å¿ƒæŒ‡æ ‡è®¡ç®—å®Œæˆ")
        print(f"   æˆæœ¬é™ä½: {summary['core_metrics']['cost_reduction_pct']:.1f}%")
        print(f"   ROIæå‡: {summary['core_metrics']['roi_improvement']:.2f}x")
        print(f"   å¹´åº¦æ•ˆç›Š: ${summary['core_metrics']['annual_benefit']:,.0f}")
    else:
        print("âš ï¸  è­¦å‘Š: ç¼ºå°‘Day 7æˆ–Day 8æ•°æ®ï¼Œæ ¸å¿ƒæŒ‡æ ‡è®¡ç®—ä¸å®Œæ•´")
        summary['core_metrics'] = {}
    
    print()
    
    # 4. å†³ç­–åˆ†æç»Ÿè®¡
    if decision_df is not None:
        print("4ï¸âƒ£  ç”Ÿæˆå†³ç­–åˆ†æç»Ÿè®¡...")
        
        summary['decision_stats'] = {
            'total_decisions': len(decision_df),
            'avg_rebalance_cost': decision_df['rebalance_cost'].mean(),
            'avg_num_moves': decision_df['num_moves'].mean(),
            'total_served': decision_df['total_served'].sum(),
            'total_cost': decision_df['rebalance_cost'].sum()
        }
        
        # æ—¶é—´æ¨¡å¼
        hourly_cost = decision_df.groupby('hour')['rebalance_cost'].sum()
        summary['hourly_pattern'] = {
            'peak_hours': hourly_cost.nlargest(5).index.tolist(),
            'low_hours': hourly_cost.nsmallest(5).index.tolist(),
            'hourly_cost': hourly_cost.to_dict()
        }
        
        print(f"âœ… å†³ç­–ç»Ÿè®¡å®Œæˆ")
        print(f"   æ€»å†³ç­–æ•°: {summary['decision_stats']['total_decisions']}")
        print(f"   å¹³å‡æˆæœ¬: ${summary['decision_stats']['avg_rebalance_cost']:.2f}")
    
    print()
    
    # 5. ä¿å­˜æ±‡æ€»æ•°æ®
    print("5ï¸âƒ£  ä¿å­˜æ±‡æ€»æ•°æ®...")
    
    with open(data_dir / "summary.pkl", 'wb') as f:
        pickle.dump(summary, f)
    
    # åŒæ—¶ä¿å­˜ä¸ºJSONï¼ˆä¾¿äºè°ƒè¯•ï¼‰
    import json
    
    # è½¬æ¢numpyç±»å‹ä¸ºPythonåŸç”Ÿç±»å‹
    def convert_to_serializable(obj):
        if isinstance(obj, (np.integer, np.floating)):
            return float(obj)
        if isinstance(obj, (np.bool_, bool)):
            return bool(obj)
        if isinstance(obj, np.ndarray):
            return obj.tolist()
        if isinstance(obj, pd.DataFrame):
            # å¤„ç† MultiIndex åˆ—åï¼Œè½¬ä¸ºå¯åºåˆ—åŒ–çš„å­—ç¬¦ä¸²åˆ—å
            df = obj.copy()
            new_cols = []
            for c in df.columns:
                if isinstance(c, tuple):
                    # è¿‡æ»¤ None å¹¶ç”¨ä¸‹åˆ’çº¿è¿æ¥
                    new_cols.append("_".join([str(x) for x in c if x is not None]))
                else:
                    new_cols.append(str(c))
            df.columns = new_cols
            # è¿”å›åˆ— -> åˆ—è¡¨ çš„å½¢å¼ï¼Œé¿å…åµŒå¥— tuple ä½œä¸º key
            return df.to_dict(orient="list")
        if isinstance(obj, dict):
            out = {}
            for k, v in obj.items():
                # å¼ºåˆ¶å°†éåŸºæœ¬ç±»å‹é”®è½¬æ¢ä¸ºå­—ç¬¦ä¸²
                if not isinstance(k, (str, int, float, bool, type(None))):
                    key = str(k)
                else:
                    key = k
                out[key] = convert_to_serializable(v)
            return out
        if isinstance(obj, list):
            return [convert_to_serializable(i) for i in obj]
        return obj
    
    summary_json = convert_to_serializable(summary)
    
    with open(data_dir / "summary.json", 'w') as f:
        json.dump(summary_json, f, indent=2)
    
    print(f"âœ… æ±‡æ€»æ•°æ®å·²ä¿å­˜")
    print()
    
    # 6. å¤åˆ¶å¯è§†åŒ–å›¾è¡¨
    print("6ï¸âƒ£  å¤åˆ¶å¯è§†åŒ–å›¾è¡¨...")
    
    viz_dir = project_root / "results" / "day9_visualizations"
    if viz_dir.exists():
        import shutil
        plot_files = list(viz_dir.glob("*.png"))
        
        for plot_file in plot_files:
            dest = assets_dir / plot_file.name
            shutil.copy2(plot_file, dest)
        
        print(f"âœ… å¤åˆ¶äº†{len(plot_files)}ä¸ªå›¾è¡¨")
    else:
        print("âš ï¸  è­¦å‘Š: æ‰¾ä¸åˆ°å¯è§†åŒ–å›¾è¡¨ç›®å½•")
    
    print()
    
    # 7. ç”Ÿæˆé…ç½®æ–‡ä»¶
    print("7ï¸âƒ£  ç”ŸæˆDashboardé…ç½®...")
    
    config = {
        'title': 'å…±äº«å•è½¦æ™ºèƒ½è°ƒåº¦ç³»ç»Ÿ',
        'subtitle': 'åŸºäºå¼ºåŒ–å­¦ä¹ çš„æˆæœ¬ä¼˜åŒ–æ–¹æ¡ˆ',
        'version': '1.0',
        'last_updated': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
        'data_files': {
            'comparison': 'data/comparison.csv',
            'decisions': 'data/decisions.csv' if decision_df is not None else None,
            'summary': 'data/summary.pkl'
        },
        'plot_files': [f.name for f in assets_dir.glob("*.png")]
    }
    
    with open(dashboard_dir / "config.json", 'w') as f:
         json.dump(config, f, indent=2)
    
    print(f"âœ… é…ç½®æ–‡ä»¶å·²ç”Ÿæˆ")
    print()
    
    # 8. æ€»ç»“
    print("="*70)
    print("âœ… Dashboardæ•°æ®å‡†å¤‡å®Œæˆï¼")
    print("="*70)
    print()
    print("ğŸ“‚ è¾“å‡ºæ–‡ä»¶:")
    print(f"  - {data_dir / 'comparison.csv'}")
    if decision_df is not None:
        print(f"  - {data_dir / 'decisions.csv'}")
    print(f"  - {data_dir / 'summary.pkl'}")
    print(f"  - {data_dir / 'summary.json'}")
    print(f"  - {dashboard_dir / 'config.json'}")
    print(f"  - {len(list(assets_dir.glob('*.png')))}ä¸ªå›¾è¡¨")
    print()
    print("ğŸš€ ä¸‹ä¸€æ­¥:")
    print("  cd dashboard")
    print("  streamlit run app.py")
    print()
    
    return True


def main():
    try:
        success = prepare_dashboard_data()
        return 0 if success else 1
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return 1


if __name__ == "__main__":
    sys.exit(main())