#!/usr/bin/env python3
"""
Day 8 - PPOè¯Šæ–­åˆ†æè„šæœ¬
åˆ†æPPOçš„è°ƒåº¦å†³ç­–æ¨¡å¼ï¼Œæ‰¾å‡ºè¿‡åº¦è°ƒåº¦çš„åŸå› 
"""

import os
import sys
import argparse
from datetime import datetime
import numpy as np
import pandas as pd
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from stable_baselines3 import PPO
from simulator.bike_env import BikeRebalancingEnv
# å°è¯•å¯¼å…¥ simulator ä¸­çš„ baseline å®ç°ï¼›ä¸å­˜åœ¨åˆ™å›é€€åˆ° policies ä¸­çš„å®ç°
try:
    from simulator.baseline_strategies import ProportionalOptimizedStrategy  # type: ignore
    _HAS_SIM_BASELINE = True
except Exception:
    _HAS_SIM_BASELINE = False
    ProportionalOptimizedStrategy = None

from simulator.utils import load_config


def parse_args():
    parser = argparse.ArgumentParser(description='PPOè¯Šæ–­åˆ†æ')
    parser.add_argument('--model', type=str, required=True,
                       help='PPOæ¨¡å‹è·¯å¾„')
    parser.add_argument('--episodes', type=int, default=5,
                       help='è¯„ä¼°è½®æ•°')
    parser.add_argument('--quick', action='store_true',
                       help='å¿«é€Ÿæ¨¡å¼ï¼ˆåªè¯„ä¼°æ ¸å¿ƒæŒ‡æ ‡ï¼‰')
    return parser.parse_args()


def collect_action_details(env, policy, episodes=5):
    """æ”¶é›†PPOçš„è¯¦ç»†è°ƒåº¦å†³ç­–"""
    action_data = []
    
    for ep in range(episodes):
        obs, _ = env.reset()
        done = False
        step = 0
        
        while not done:
            action, _ = policy.predict(obs, deterministic=True)
            next_obs, reward, done, truncated, info = env.step(action)
            
            # è®°å½•è°ƒåº¦è¯¦æƒ…
            rebalance_cost = info.get('rebalance_cost', 0)
            num_rebalances = np.sum(action > 0) if hasattr(action, '__len__') else (1 if action > 0 else 0)
            
            action_data.append({
                'episode': ep + 1,
                'step': step,
                'hour': info.get('hour', 0),
                'rebalance_cost': rebalance_cost,
                'num_rebalances': num_rebalances,
                'total_demand': info.get('total_demand', 0),
                'total_served': info.get('total_served', 0),
                'service_rate': info.get('service_rate', 0),
                'reward': reward
            })
            
            obs = next_obs
            step += 1
            
            if done or truncated:
                break
    
    return pd.DataFrame(action_data)


def collect_baseline_details(env, episodes=5):
    """æ”¶é›†åŸºçº¿ç­–ç•¥çš„è¯¦ç»†è°ƒåº¦å†³ç­–ï¼ˆæ”¯æŒ simulator æˆ– policies å›é€€ï¼‰"""
    action_data = []
    if _HAS_SIM_BASELINE and ProportionalOptimizedStrategy is not None:
        strategy = ProportionalOptimizedStrategy(env.num_zones)
        _strategy_type = 'simulator'
    else:
        from policies.baseline_policies import ProportionalRefillPolicy
        # ä½¿ç”¨ env å†…éƒ¨çš„ configï¼ˆå·²ç”± BikeRebalancingEnv è§£æï¼‰
        cfg = getattr(env, "config", None)
        strategy = ProportionalRefillPolicy(cfg if isinstance(cfg, dict) else {})
        _strategy_type = 'policy'
    
    for ep in range(episodes):
        obs, _ = env.reset()
        done = False
        step = 0
        
        while not done:
            try:
                if _strategy_type == 'simulator':
                    action = strategy.select_action(obs, env)
                else:
                    action = strategy.select_action(obs)
            except TypeError:
                # å®¹é”™ï¼šå°è¯•ä¸¤ç§ç­¾å
                try:
                    action = strategy.select_action(obs)
                except Exception:
                    action = strategy.select_action(obs, env)
            next_obs, reward, done, truncated, info = env.step(action)
            
            rebalance_cost = info.get('rebalance_cost', 0)
            num_rebalances = np.sum(action > 0) if hasattr(action, '__len__') else (1 if action > 0 else 0)
            
            action_data.append({
                'episode': ep + 1,
                'step': step,
                'hour': info.get('hour', 0),
                'rebalance_cost': rebalance_cost,
                'num_rebalances': num_rebalances,
                'total_demand': info.get('total_demand', 0),
                'total_served': info.get('total_served', 0),
                'service_rate': info.get('service_rate', 0),
                'reward': reward
            })
            
            obs = next_obs
            step += 1
            
            if done or truncated:
                break
    
    return pd.DataFrame(action_data)


def analyze_action_patterns(ppo_data, baseline_data):
    """åˆ†æè°ƒåº¦æ¨¡å¼çš„å·®å¼‚"""
    analysis = {}
    
    # 1. è°ƒåº¦é¢‘ç‡å¯¹æ¯”
    analysis['ppo_avg_rebalances_per_step'] = ppo_data['num_rebalances'].mean()
    analysis['baseline_avg_rebalances_per_step'] = baseline_data['num_rebalances'].mean()
    analysis['rebalance_frequency_ratio'] = (
        analysis['ppo_avg_rebalances_per_step'] / 
        max(analysis['baseline_avg_rebalances_per_step'], 0.01)
    )
    
    # 2. æˆæœ¬å¯¹æ¯”
    analysis['ppo_avg_cost_per_step'] = ppo_data['rebalance_cost'].mean()
    analysis['baseline_avg_cost_per_step'] = baseline_data['rebalance_cost'].mean()
    analysis['cost_ratio'] = (
        analysis['ppo_avg_cost_per_step'] / 
        max(analysis['baseline_avg_cost_per_step'], 0.01)
    )
    
    # 3. æ€»æˆæœ¬
    analysis['ppo_total_cost'] = ppo_data.groupby('episode')['rebalance_cost'].sum().mean()
    analysis['baseline_total_cost'] = baseline_data.groupby('episode')['rebalance_cost'].sum().mean()
    
    # 4. æœåŠ¡ç‡å¯¹æ¯”
    analysis['ppo_avg_service_rate'] = ppo_data['service_rate'].mean()
    analysis['baseline_avg_service_rate'] = baseline_data['service_rate'].mean()
    
    # 5. æˆæœ¬æ•ˆç‡ï¼ˆcost per service rateï¼‰
    ppo_total_served = ppo_data.groupby('episode')['total_served'].sum().mean()
    baseline_total_served = baseline_data.groupby('episode')['total_served'].sum().mean()
    
    analysis['ppo_cost_per_serve'] = analysis['ppo_total_cost'] / max(ppo_total_served, 1)
    analysis['baseline_cost_per_serve'] = analysis['baseline_total_cost'] / max(baseline_total_served, 1)
    
    # 6. æ—¶é—´åˆ†å¸ƒåˆ†æ
    ppo_hourly = ppo_data.groupby('hour')['rebalance_cost'].mean()
    baseline_hourly = baseline_data.groupby('hour')['rebalance_cost'].mean()
    analysis['ppo_peak_hour'] = ppo_hourly.idxmax()
    analysis['baseline_peak_hour'] = baseline_hourly.idxmax()
    
    return analysis


def generate_diagnosis_report(analysis, output_dir):
    """ç”Ÿæˆè¯Šæ–­æŠ¥å‘Š"""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    report_path = output_dir / f"diagnosis_summary_{timestamp}.txt"
    
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write("="*70 + "\n")
        f.write("PPOè¯Šæ–­åˆ†ææŠ¥å‘Š\n")
        f.write("="*70 + "\n\n")
        
        f.write("1ï¸âƒ£  è°ƒåº¦é¢‘ç‡å¯¹æ¯”\n")
        f.write(f"   PPOå¹³å‡è°ƒåº¦æ¬¡æ•°/æ­¥: {analysis['ppo_avg_rebalances_per_step']:.2f}\n")
        f.write(f"   åŸºçº¿å¹³å‡è°ƒåº¦æ¬¡æ•°/æ­¥: {analysis['baseline_avg_rebalances_per_step']:.2f}\n")
        f.write(f"   é¢‘ç‡æ¯”ç‡: {analysis['rebalance_frequency_ratio']:.2f}x\n\n")
        
        f.write("2ï¸âƒ£  æˆæœ¬å¯¹æ¯”\n")
        f.write(f"   PPOå¹³å‡æˆæœ¬/æ­¥: ${analysis['ppo_avg_cost_per_step']:.2f}\n")
        f.write(f"   åŸºçº¿å¹³å‡æˆæœ¬/æ­¥: ${analysis['baseline_avg_cost_per_step']:.2f}\n")
        f.write(f"   æˆæœ¬æ¯”ç‡: {analysis['cost_ratio']:.2f}x\n\n")
        
        f.write("3ï¸âƒ£  æ€»æˆæœ¬\n")
        f.write(f"   PPOæ€»æˆæœ¬: ${analysis['ppo_total_cost']:.2f}\n")
        f.write(f"   åŸºçº¿æ€»æˆæœ¬: ${analysis['baseline_total_cost']:.2f}\n")
        f.write(f"   æˆæœ¬å·®å¼‚: ${analysis['ppo_total_cost'] - analysis['baseline_total_cost']:.2f}\n\n")
        
        f.write("4ï¸âƒ£  æœåŠ¡ç‡å¯¹æ¯”\n")
        f.write(f"   PPOå¹³å‡æœåŠ¡ç‡: {analysis['ppo_avg_service_rate']*100:.2f}%\n")
        f.write(f"   åŸºçº¿å¹³å‡æœåŠ¡ç‡: {analysis['baseline_avg_service_rate']*100:.2f}%\n\n")
        
        f.write("5ï¸âƒ£  æˆæœ¬æ•ˆç‡\n")
        f.write(f"   PPOæˆæœ¬/æœåŠ¡: ${analysis['ppo_cost_per_serve']:.4f}\n")
        f.write(f"   åŸºçº¿æˆæœ¬/æœåŠ¡: ${analysis['baseline_cost_per_serve']:.4f}\n")
        f.write(f"   æ•ˆç‡æ¯”: {analysis['ppo_cost_per_serve']/max(analysis['baseline_cost_per_serve'], 0.0001):.2f}x\n\n")
        
        f.write("="*70 + "\n")
        f.write("ğŸ” æ ¸å¿ƒå‘ç°\n")
        f.write("="*70 + "\n\n")
        
        if analysis['rebalance_frequency_ratio'] > 1.5:
            f.write("âš ï¸  **è¿‡åº¦è°ƒåº¦é—®é¢˜**\n")
            f.write(f"   PPOçš„è°ƒåº¦é¢‘ç‡æ˜¯åŸºçº¿çš„{analysis['rebalance_frequency_ratio']:.1f}å€\n")
            f.write("   å»ºè®®ï¼šå¢åŠ å¥–åŠ±å‡½æ•°ä¸­çš„æˆæœ¬æƒé‡\n\n")
        
        if analysis['cost_ratio'] > 1.5:
            f.write("âš ï¸  **æˆæœ¬è¿‡é«˜é—®é¢˜**\n")
            f.write(f"   PPOçš„è°ƒåº¦æˆæœ¬æ˜¯åŸºçº¿çš„{analysis['cost_ratio']:.1f}å€\n")
            f.write("   å»ºè®®ï¼šé‡æ–°è®¾è®¡å¥–åŠ±å‡½æ•°ï¼Œå¢å¼ºæˆæœ¬æ•æ„Ÿæ€§\n\n")
        
        if abs(analysis['ppo_avg_service_rate'] - analysis['baseline_avg_service_rate']) < 0.005:
            f.write("â„¹ï¸  **æœåŠ¡ç‡ç›¸è¿‘**\n")
            f.write("   PPOå’ŒåŸºçº¿çš„æœåŠ¡ç‡æ¥è¿‘ï¼Œä½†æˆæœ¬æ›´é«˜\n")
            f.write("   è¯´æ˜ï¼šPPOè¿‡åº¦è¿½æ±‚æœåŠ¡ç‡ï¼Œå¿½è§†äº†æˆæœ¬æ•ˆç›Š\n\n")
        
        f.write("="*70 + "\n")
        f.write("ğŸ’¡ æ”¹è¿›å»ºè®®\n")
        f.write("="*70 + "\n\n")
        
        f.write("1. **å¥–åŠ±å‡½æ•°ä¼˜åŒ–**\n")
        current_cost_weight = 1.0  # å½“å‰æƒé‡
        suggested_cost_weight = current_cost_weight * analysis['cost_ratio']
        f.write(f"   å½“å‰æˆæœ¬æƒé‡: {current_cost_weight}\n")
        f.write(f"   å»ºè®®æˆæœ¬æƒé‡: {suggested_cost_weight:.1f}\n")
        f.write(f"   æ–°å¥–åŠ±å‡½æ•°: reward = revenue - 5.0*penalty - {suggested_cost_weight:.1f}*cost\n\n")
        
        f.write("2. **è¶…å‚æ•°è°ƒæ•´**\n")
        f.write("   - é™ä½å­¦ä¹ ç‡: 3e-4 â†’ 1e-4\n")
        f.write("   - å¢åŠ é‡‡æ ·æ­¥æ•°: 2048 â†’ 4096\n")
        f.write("   - å¢åŠ æ‰¹å¤§å°: 64 â†’ 128\n\n")
        
        f.write("3. **è®­ç»ƒç­–ç•¥**\n")
        f.write("   - å¢åŠ è®­ç»ƒæ­¥æ•°: 100k â†’ 150k\n")
        f.write("   - ä½¿ç”¨å¤šä¸ªéšæœºç§å­\n")
        f.write("   - ç›‘æ§è®­ç»ƒæ›²çº¿ç¨³å®šæ€§\n\n")
    
    print(f"ğŸ’¾ è¯Šæ–­æŠ¥å‘Šå·²ä¿å­˜: {report_path}")
    return report_path


def main():
    args = parse_args()
    
    print("="*70)
    print("Day 8 - PPOè¯Šæ–­åˆ†æ")
    print("="*70)
    print()
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = Path("results/ppo_diagnosis")
    output_dir.mkdir(parents=True, exist_ok=True)
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir.absolute()}")
    print()
    
    # åŠ è½½é…ç½®
    print("ğŸ“„ åŠ è½½é…ç½®...")
    config = load_config()
    print("âœ… é…ç½®åŠ è½½æˆåŠŸ")
    print()
    
    # åŠ è½½PPOæ¨¡å‹
    print("="*70)
    print("åŠ è½½PPOæ¨¡å‹")
    print("="*70)
    print()
    print(f"ğŸ“¦ æ¨¡å‹è·¯å¾„: {args.model}")
    
    if not os.path.exists(args.model):
        print(f"âŒ é”™è¯¯: æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {args.model}")
        return 1
    
    model = PPO.load(args.model)
    print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
    print()
    
    # åˆ›å»ºç¯å¢ƒ
    print("="*70)
    print("æ”¶é›†PPOè°ƒåº¦æ•°æ®")
    print("="*70)
    print()
    # å…¼å®¹ config_dict å‚æ•°ï¼šload_config() è¿”å› dict æ—¶ä½¿ç”¨ config_dict
    if isinstance(config, dict):
        env = BikeRebalancingEnv(config_dict=config, scenario='default')
    else:
        env = BikeRebalancingEnv(config=config, scenario='default')
    print(f"ğŸ”„ è¿è¡Œ{args.episodes}è½®æ¨¡æ‹Ÿ...")
    ppo_data = collect_action_details(env, model, episodes=args.episodes)
    print(f"âœ… PPOæ•°æ®æ”¶é›†å®Œæˆ: {len(ppo_data)}æ¡è®°å½•")
    print()
    
    # æ”¶é›†åŸºçº¿æ•°æ®
    print("="*70)
    print("æ”¶é›†åŸºçº¿è°ƒåº¦æ•°æ®")
    print("="*70)
    print()
    if isinstance(config, dict):
        env_baseline = BikeRebalancingEnv(config_dict=config, scenario='default')
    else:
        env_baseline = BikeRebalancingEnv(config=config, scenario='default')
    print(f"ğŸ”„ è¿è¡Œ{args.episodes}è½®æ¨¡æ‹Ÿ...")
    baseline_data = collect_baseline_details(env_baseline, episodes=args.episodes)
    print(f"âœ… åŸºçº¿æ•°æ®æ”¶é›†å®Œæˆ: {len(baseline_data)}æ¡è®°å½•")
    print()
    
    # ä¿å­˜è¯¦ç»†æ•°æ®
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    ppo_data.to_csv(output_dir / f"ppo_actions_{timestamp}.csv", index=False)
    baseline_data.to_csv(output_dir / f"baseline_actions_{timestamp}.csv", index=False)
    print(f"ğŸ’¾ è¯¦ç»†æ•°æ®å·²ä¿å­˜")
    print()
    
    # åˆ†ææ¨¡å¼
    print("="*70)
    print("åˆ†æè°ƒåº¦æ¨¡å¼")
    print("="*70)
    print()
    analysis = analyze_action_patterns(ppo_data, baseline_data)
    
    # æ‰“å°å…³é”®æŒ‡æ ‡
    print(f"PPOè°ƒåº¦é¢‘ç‡: {analysis['ppo_avg_rebalances_per_step']:.2f} æ¬¡/æ­¥")
    print(f"åŸºçº¿è°ƒåº¦é¢‘ç‡: {analysis['baseline_avg_rebalances_per_step']:.2f} æ¬¡/æ­¥")
    print(f"é¢‘ç‡æ¯”ç‡: {analysis['rebalance_frequency_ratio']:.2f}x")
    print()
    print(f"PPOå¹³å‡æˆæœ¬: ${analysis['ppo_avg_cost_per_step']:.2f}/æ­¥")
    print(f"åŸºçº¿å¹³å‡æˆæœ¬: ${analysis['baseline_avg_cost_per_step']:.2f}/æ­¥")
    print(f"æˆæœ¬æ¯”ç‡: {analysis['cost_ratio']:.2f}x")
    print()
    print(f"PPOæ€»æˆæœ¬: ${analysis['ppo_total_cost']:.2f}")
    print(f"åŸºçº¿æ€»æˆæœ¬: ${analysis['baseline_total_cost']:.2f}")
    print()
    
    # ç”ŸæˆæŠ¥å‘Š
    print("="*70)
    print("ç”Ÿæˆè¯Šæ–­æŠ¥å‘Š")
    print("="*70)
    print()
    report_path = generate_diagnosis_report(analysis, output_dir)
    print()
    print("ğŸ’¡ è¯·æŸ¥çœ‹è¯Šæ–­æŠ¥å‘Šäº†è§£è¯¦ç»†åˆ†æå’Œæ”¹è¿›å»ºè®®")
    print()
    
    print("="*70)
    print("âœ… Day 8 è¯Šæ–­ä»»åŠ¡å®Œæˆï¼")
    print("="*70)
    
    return 0


if __name__ == "__main__":
    sys.exit(main())