# å…±äº«å•è½¦å¤§æ•°æ®åˆ†æžé¡¹ç›® - Day 1 å®Œæˆæ€»ç»“

**é¡¹ç›®åç§°**: å…±äº«å•è½¦æ•°æ®åˆ†æžä¸Žå¼ºåŒ–å­¦ä¹ è°ƒåº¦  
**æ—¥æœŸ**: 2025-10-26ï¼ˆå‘¨å…­ï¼‰  
**é˜¶æ®µ**: M1 æ•°æ®ä¸Žåˆ†æž - Day 1/3  
**å®Œæˆåº¦**: âœ… 100%

---

## ä¸€ã€ä»Šæ—¥å®Œæˆå†…å®¹

### 1.1 çŽ¯å¢ƒæ­å»ºä¸Žé…ç½® âœ…

#### **WSL2 + Ubuntu çŽ¯å¢ƒ**
- [x] å¯ç”¨WSL2å¹¶å®‰è£…Ubuntu 20.04
- [x] WSLä»ŽCç›˜è¿ç§»è‡³Eç›˜ï¼ˆé‡Šæ”¾6.7GBç©ºé—´ï¼‰
- [x] é…ç½®SSHæœåŠ¡ï¼Œå®žçŽ°å…å¯†ç™»å½•
- [x] è§£å†³ç½‘ç»œå’Œæƒé™é—®é¢˜

**æŠ€æœ¯è¦ç‚¹**:
- WSLå¯¼å‡º/å¯¼å…¥æœºåˆ¶ï¼š`wsl --export` / `wsl --import`
- é…ç½®`/etc/wsl.conf`è®¾ç½®é»˜è®¤ç”¨æˆ·
- SSHå¯†é’¥ç”Ÿæˆä¸Žauthorized_keysé…ç½®

#### **Hadoop 3.3.x åˆ†å¸ƒå¼æ–‡ä»¶ç³»ç»Ÿ**
- [x] å®‰è£…Hadoop 3.3.x
- [x] é…ç½®ä¼ªåˆ†å¸ƒå¼æ¨¡å¼
- [x] å¯åŠ¨HDFSå’ŒYARNæœåŠ¡
- [x] éªŒè¯æ‰€æœ‰å®ˆæŠ¤è¿›ç¨‹æ­£å¸¸è¿è¡Œ

**å…³é”®æœåŠ¡**:
```
NameNode          - HDFSä¸»èŠ‚ç‚¹
DataNode          - HDFSæ•°æ®èŠ‚ç‚¹  
SecondaryNameNode - HDFSæ£€æŸ¥ç‚¹èŠ‚ç‚¹
ResourceManager   - YARNèµ„æºç®¡ç†å™¨
NodeManager       - YARNèŠ‚ç‚¹ç®¡ç†å™¨
```

**æŠ€æœ¯è¦ç‚¹**:
- HDFSæž¶æž„ï¼šä¸»ä»Žæ¨¡å¼ã€å—å­˜å‚¨ã€å‰¯æœ¬æœºåˆ¶
- YARNèµ„æºè°ƒåº¦ï¼šå®¹å™¨åŒ–ä»»åŠ¡ç®¡ç†
- Hadoopé…ç½®æ–‡ä»¶ï¼šcore-site.xml, hdfs-site.xml, yarn-site.xml

#### **Apache Spark 3.3.0 è®¡ç®—å¼•æ“Ž**
- [x] å®‰è£…Spark 3.3.0-bin-hadoop3
- [x] é…ç½®çŽ¯å¢ƒå˜é‡ï¼ˆSPARK_HOMEï¼‰
- [x] éªŒè¯spark-submitå’Œpysparkå¯ç”¨

**æŠ€æœ¯è¦ç‚¹**:
- Sparkä¸ŽHadoopé›†æˆï¼šåŸºäºŽHDFSçš„æ•°æ®è¯»å†™
- PySpark APIï¼šDataFrameå’ŒRDDæ“ä½œ
- å†…å­˜è®¡ç®—ä¼˜åŠ¿ï¼šæ¯”MapReduceå¿«10-100å€

#### **Pythonå¼€å‘çŽ¯å¢ƒ**
- [x] å®‰è£…Python 3.12åŠpip
- [x] å®‰è£…æ ¸å¿ƒä¾èµ–åŒ…ï¼ˆä½¿ç”¨--break-system-packagesï¼‰

**å·²å®‰è£…åº“**:
```
pyspark==3.3.0    - Spark Python API
pandas==2.3.3     - æ•°æ®å¤„ç†
numpy==2.3.4      - æ•°å€¼è®¡ç®—
faker==37.12.0    - æ¨¡æ‹Ÿæ•°æ®ç”Ÿæˆ
pyecharts==2.0.9  - æ•°æ®å¯è§†åŒ–
flask==3.1.2      - Webæ¡†æž¶
pymysql==1.1.2    - æ•°æ®åº“è¿žæŽ¥
```

---

### 1.2 é¡¹ç›®ç»“æž„æ­å»º âœ…

#### **ç›®å½•æž¶æž„**
```
~/bike-sharing-analysis/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/              # KaggleåŽŸå§‹æ•°æ®ï¼ˆhour.csv, day.csvï¼‰
â”‚   â”œâ”€â”€ processed/        # ä¸­é—´å¤„ç†æ•°æ®
â”‚   â””â”€â”€ generated/        # ç”Ÿæˆçš„10ä¸‡æ¡è®¢å• â­
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ generate_bike_data.py    # æ•°æ®ç”Ÿæˆè„šæœ¬
â”‚   â””â”€â”€ upload_to_hdfs.sh        # HDFSä¸Šä¼ è„šæœ¬
â”œâ”€â”€ analysis/             # Sparkåˆ†æžä»£ç ï¼ˆå¾…å¼€å‘ï¼‰
â”œâ”€â”€ simulator/            # Gymè°ƒåº¦çŽ¯å¢ƒï¼ˆå¾…å¼€å‘ï¼‰
â”œâ”€â”€ rl/                   # å¼ºåŒ–å­¦ä¹ è®­ç»ƒï¼ˆå¾…å¼€å‘ï¼‰
â”œâ”€â”€ web/                  # Flaskå¯è§†åŒ–ï¼ˆå¾…å¼€å‘ï¼‰
â”œâ”€â”€ results/              # åˆ†æžç»“æžœ
â””â”€â”€ README.md             # é¡¹ç›®è¯´æ˜Žæ–‡æ¡£
```

**æŠ€æœ¯è¦ç‚¹**:
- æ¨¡å—åŒ–è®¾è®¡ï¼šåˆ†ç¦»æ•°æ®ã€åˆ†æžã€æ¨¡æ‹Ÿã€RLã€å¯è§†åŒ–
- ç¬¦åˆå¤§æ•°æ®é¡¹ç›®æœ€ä½³å®žè·µ
- ä¾¿äºŽå›¢é˜Ÿåä½œå’Œç‰ˆæœ¬ç®¡ç†

---

### 1.3 æ•°æ®ç”Ÿæˆä¸Žè´¨é‡ä¿è¯ âœ…

#### **æ•°æ®è§„æ¨¡**
- **è®¢å•æ•°æ®**: 100,000æ¡ï¼ˆorders_100k.csvï¼‰
- **ç”¨æˆ·æ•°æ®**: 10,000æ¡ï¼ˆuser_info_10k.csvï¼‰
- **å•è½¦æ•°æ®**: 5,000æ¡ï¼ˆbike_info_5k.csvï¼‰

#### **æ•°æ®ç”Ÿæˆç­–ç•¥**

**åŸºäºŽKaggleçœŸå®žéœ€æ±‚æ¨¡åž‹**:
- æ•°æ®æºï¼šCapital Bikeshareï¼ˆåŽç››é¡¿ç‰¹åŒºï¼Œ2011-2012ï¼‰
- åŽŸå§‹æ•°æ®ï¼š17,379æ¡å°æ—¶çº§çœŸå®žæ•°æ®
- éœ€æ±‚æ¨¡åž‹ï¼š578ç§åœºæ™¯ç»„åˆï¼ˆå°æ—¶Ã—å­£èŠ‚Ã—å·¥ä½œæ—¥Ã—å¤©æ°”ï¼‰

**æŠ€æœ¯å®žçŽ°**:
```python
# éœ€æ±‚å¼ºåº¦å‡½æ•° Î»(t) çš„æž„å»º
demand_model = df_hour.groupby(['hr', 'season', 'workingday', 'weathersit'])
                      .agg({'cnt': 'mean'})

# åŸºäºŽÎ»(t)è¿›è¡Œæ³Šæ¾é‡‡æ ·
D_{z,t} ~ Poisson(Î»_{z,t})
```

**æ•°æ®ç‰¹å¾å·¥ç¨‹**:
1. **æ—¶é—´ç‰¹å¾**: å¹´ã€æœˆã€æ—¥ã€å°æ—¶ã€æ˜ŸæœŸã€å·¥ä½œæ—¥æ ‡è¯†
2. **å¤©æ°”ç‰¹å¾**: å­£èŠ‚(1-4)ã€å¤©æ°”(1-4)ã€æ¸©åº¦ã€æ¹¿åº¦ã€é£Žé€Ÿï¼ˆå½’ä¸€åŒ–ï¼‰
3. **ç©ºé—´ç‰¹å¾**: èµ·æ­¢åŒºåŸŸã€ç»çº¬åº¦åæ ‡ã€éª‘è¡Œè·ç¦»
4. **ä¸šåŠ¡ç‰¹å¾**: å•è½¦ç±»åž‹ã€éª‘è¡Œæ—¶é•¿ã€è´¹ç”¨

#### **åŽç››é¡¿ç‰¹åŒºæœåŠ¡åŒºåŸŸè®¾è®¡**

| åŒºåŸŸä»£ç  | åŒºåŸŸåç§° | ç»çº¬åº¦ | æƒé‡ | ç‰¹å¾ |
|---------|---------|--------|------|------|
| A_Capitol_Hill | å›½ä¼šå±± | (38.8899, -77.0091) | 25% | æ”¿åºœåŒºï¼Œå·¥ä½œæ—¥é«˜å³° |
| B_Downtown | å¸‚ä¸­å¿ƒ | (38.9072, -77.0369) | 25% | å•†åŠ¡åŒºï¼Œå…¨å¤©æµé‡å¤§ |
| C_Georgetown | ä¹”æ²»åŸŽ | (38.9076, -77.0723) | 15% | å•†ä¸š+å±…ä½æ··åˆ |
| D_Dupont_Circle | æœé‚¦çŽ¯å²› | (38.9097, -77.0436) | 15% | å±…ä½+å¤œç”Ÿæ´» |
| E_Shaw | è‚–åŒº | (38.9129, -77.0262) | 10% | æ–‡åŒ–è‰ºæœ¯åŒº |
| F_Navy_Yard | æµ·å†›èˆ¹åž | (38.8764, -76.9951) | 10% | æ»¨æ°´åŒºï¼Œä½“è‚²åœºé¦† |

**æŠ€æœ¯è¦ç‚¹**:
- åŒºåŸŸæƒé‡å½±å“éœ€æ±‚åˆ†å¸ƒ
- è€ƒè™‘åŒºåŸŸåŠŸèƒ½ç‰¹ç‚¹ï¼ˆå·¥ä½œæ—¥vså‘¨æœ«å·®å¼‚ï¼‰
- è·ç¦»è®¡ç®—ï¼šåŸºäºŽç»çº¬åº¦çš„æ¬§æ°è·ç¦»è¿‘ä¼¼

#### **æ•°æ®è´¨é‡éªŒè¯**

**ç»Ÿè®¡åˆ†å¸ƒæ£€æŸ¥**:
- âœ… å­£èŠ‚åˆ†å¸ƒå‡åŒ€ï¼šå†¬25.0%, æ˜¥25.2%, å¤25.0%, ç§‹24.7%
- âœ… å¤©æ°”åˆ†å¸ƒåˆç†ï¼šæ™´50%, å¤šäº‘30%, å°é›¨15%, å¤§é›¨5%
- âœ… å·¥ä½œæ—¥å æ¯”71.2%ï¼ˆç¬¦åˆçœŸå®ž5:2æ¯”ä¾‹ï¼‰
- âœ… åŒºåŸŸåˆ†å¸ƒç¬¦åˆæƒé‡ï¼šDowntown 25%, Capitol Hill 24.9%

**ä¸šåŠ¡åˆç†æ€§æ£€æŸ¥**:
- âœ… å¹³å‡éª‘è¡Œæ—¶é•¿ï¼š16.5åˆ†é’Ÿï¼ˆç¬¦åˆçŸ­é€”å‡ºè¡Œç‰¹å¾ï¼‰
- âœ… å¹³å‡éª‘è¡Œè·ç¦»ï¼š3.24å…¬é‡Œï¼ˆåŸŽå¸‚ä»£æ­¥è·ç¦»ï¼‰
- âœ… å¹³å‡è´¹ç”¨ï¼š$4.00ï¼ˆåˆç†å®šä»·ï¼‰
- âœ… é«˜å³°æ—¶æ®µè¯†åˆ«ï¼š17:00-18:00, 22:00-23:00

**æ•°æ®ä¸€è‡´æ€§æ£€æŸ¥**:
- âœ… æ— ç¼ºå¤±å€¼
- âœ… æ—¶é—´èŒƒå›´å®Œæ•´ï¼ˆ2011-01-01è‡³2012-12-31ï¼‰
- âœ… ç»çº¬åº¦åœ¨åŽç››é¡¿ç‰¹åŒºåˆç†èŒƒå›´å†…
- âœ… èµ·æ­¢æ—¶é—´é€»è¾‘æ­£ç¡®ï¼ˆend_time > start_timeï¼‰

---

### 1.4 HDFSæ•°æ®å­˜å‚¨ âœ…

#### **HDFSç›®å½•ç»“æž„**
```
/bike_data/
â”œâ”€â”€ raw/                 # åŽŸå§‹æ•°æ®
â”‚   â”œâ”€â”€ orders_100k.csv
â”‚   â”œâ”€â”€ user_info_10k.csv
â”‚   â””â”€â”€ bike_info_5k.csv
â”œâ”€â”€ processed/           # å¤„ç†åŽæ•°æ®ï¼ˆå¾…ç”Ÿæˆï¼‰
â””â”€â”€ results/             # åˆ†æžç»“æžœï¼ˆå¾…ç”Ÿæˆï¼‰
```

**ä¸Šä¼ å‘½ä»¤**:
```bash
hdfs dfs -put data/generated/orders_100k.csv /bike_data/raw/
hdfs dfs -put data/generated/user_info_10k.csv /bike_data/raw/
hdfs dfs -put data/generated/bike_info_5k.csv /bike_data/raw/
```

**æŠ€æœ¯è¦ç‚¹**:
- HDFSåˆ†å¸ƒå¼å­˜å‚¨ï¼šé«˜å®¹é”™ã€é«˜åžå
- æ•°æ®å‰¯æœ¬æœºåˆ¶ï¼šé»˜è®¤3å‰¯æœ¬ä¿è¯å¯é æ€§
- å—å¤§å°ï¼š128MBï¼Œé€‚åˆå¤§æ–‡ä»¶å­˜å‚¨

---

## äºŒã€æ ¸å¿ƒæŠ€æœ¯è¦ç‚¹æ€»ç»“

### 2.1 å¤§æ•°æ®æŠ€æœ¯æ ˆ

#### **å­˜å‚¨å±‚ï¼šHadoop HDFS**
- **æž¶æž„**: ä¸»ä»Žæ¨¡å¼ï¼ˆNameNode + DataNodeï¼‰
- **ç‰¹ç‚¹**: 
  - é«˜å®¹é”™ï¼šæ•°æ®å¤šå‰¯æœ¬
  - é«˜åžåï¼šé€‚åˆæ‰¹å¤„ç†
  - å¯æ‰©å±•ï¼šæ¨ªå‘æ‰©å±•å­˜å‚¨
- **åº”ç”¨**: å­˜å‚¨10ä¸‡æ¡è®¢å•æ•°æ®åŠåŽç»­åˆ†æžç»“æžœ

#### **è®¡ç®—å±‚ï¼šApache Spark**
- **æž¶æž„**: RDD â†’ DataFrame â†’ Dataset APIæ¼”è¿›
- **ç‰¹ç‚¹**:
  - å†…å­˜è®¡ç®—ï¼šDAGæ‰§è¡Œå¼•æ“Ž
  - æƒ°æ€§æ±‚å€¼ï¼šä¼˜åŒ–æ‰§è¡Œè®¡åˆ’
  - å¤šè¯­è¨€æ”¯æŒï¼šScala/Python/Java/R
- **åº”ç”¨**: æ•°æ®æ¸…æ´—ã€èšåˆåˆ†æžã€ç‰¹å¾å·¥ç¨‹

#### **å¼€å‘å±‚ï¼šPySpark + Pandas**
- **PySpark**: å¤§è§„æ¨¡æ•°æ®å¤„ç†ï¼ˆåˆ†å¸ƒå¼ï¼‰
- **Pandas**: æœ¬åœ°æ•°æ®åˆ†æžï¼ˆå•æœºï¼‰
- **ååŒ**: Sparkå¤„ç†åŽè½¬Pandasè¿›è¡Œç»†ç²’åº¦åˆ†æž

---

### 2.2 æ•°æ®å·¥ç¨‹æ–¹æ³•

#### **éœ€æ±‚å»ºæ¨¡ - Î»(t)å‡½æ•°**

**æ•°å­¦æ¨¡åž‹**:
```
log Î»_t = Î²â‚€ + Î²_hour[h] + Î²_season[s] + Î²_weekday[w] + Î²_weather[k]
```

**ç‰¹å¾ç»´åº¦**:
- `h`: å°æ—¶ï¼ˆ0-23ï¼Œ24ä¸ªæ°´å¹³ï¼‰
- `s`: å­£èŠ‚ï¼ˆ1-4ï¼Œ4ä¸ªæ°´å¹³ï¼‰
- `w`: å·¥ä½œæ—¥ï¼ˆ0-1ï¼Œ2ä¸ªæ°´å¹³ï¼‰
- `k`: å¤©æ°”ï¼ˆ1-4ï¼Œ4ä¸ªæ°´å¹³ï¼‰

**å‚æ•°ä¼°è®¡æ–¹æ³•**ï¼ˆDay 2å¾…å®žçŽ°ï¼‰:
1. **Poissonå›žå½’**: ä¼ ç»Ÿç»Ÿè®¡æ–¹æ³•ï¼Œå¯è§£é‡Šæ€§å¼º
2. **Gradient Boosting**: XGBoost/LightGBMï¼Œé¢„æµ‹ç²¾åº¦é«˜
3. **æ··åˆæ¨¡åž‹**: åŸºç¡€å›žå½’+æ ‘æ¨¡åž‹æ ¡æ­£

**ç©ºé—´æ‹†åˆ†**:
```
Î»_{z,t} = w_z Ã— Î»_t
```
- `w_z`: åŒºåŸŸæƒé‡ï¼ˆåæ˜ åŒºåŸŸçƒ­åº¦ï¼‰
- 6ä¸ªåŒºåŸŸï¼Œæƒé‡å’Œä¸º1

**éªŒè¯æŒ‡æ ‡**ï¼ˆDay 2å¾…è®¡ç®—ï¼‰:
- RMSE/MAEï¼šé¢„æµ‹è¯¯å·®
- RÂ²ï¼šæ‹Ÿåˆä¼˜åº¦
- é«˜å³°æ—¶æ®µæ•æ‰çŽ‡
- å‘¨æœ«/å·¥ä½œæ—¥è¶‹åŠ¿ä¸€è‡´æ€§

---

### 2.3 æ•°æ®ç”ŸæˆæŠ€æœ¯ç»†èŠ‚

#### **éšæœºæ•°æŽ§åˆ¶**
```python
np.random.seed(42)      # NumPyéšæœºç§å­
random.seed(42)         # Pythonéšæœºç§å­
Faker.seed(42)          # Fakeræ•°æ®ç”Ÿæˆç§å­
```
**ä½œç”¨**: ä¿è¯æ•°æ®å¯å¤çŽ°ï¼Œä¾¿äºŽè°ƒè¯•å’Œå¯¹æ¯”

#### **æ‰¹é‡ç”Ÿæˆç­–ç•¥**
```python
batch_size = 10000
num_batches = 10
```
**ä½œç”¨**: é¿å…å†…å­˜æº¢å‡ºï¼Œé€‚åˆå¤§è§„æ¨¡æ•°æ®ç”Ÿæˆ

#### **æ—¶é—´ç”Ÿæˆé€»è¾‘**
```python
# éšæœºç”Ÿæˆ2011-2012å¹´é—´çš„ä»»æ„æ—¶åˆ»
random_datetime = start_date + timedelta(
    days=random.randint(0, 730),
    seconds=random.randint(0, 86400)
)
```

#### **è·ç¦»è®¡ç®—ç®€åŒ–**
```python
# åŽç››é¡¿ç‰¹åŒºçº¬åº¦çº¦38åº¦
dlat = (lat2 - lat1) Ã— 111 km  # 1åº¦çº¬åº¦â‰ˆ111km
dlng = (lng2 - lng1) Ã— 87 km   # 1åº¦ç»åº¦â‰ˆ87kmï¼ˆçº¬åº¦38åº¦ï¼‰
distance = sqrt(dlatÂ² + dlngÂ²)
```

#### **è´¹ç”¨è®¡ç®—æ¨¡åž‹**
```python
total_fee = base_fee + distance_fee + time_fee

base_fee = 2.0 (æ™®é€šè½¦) / 3.0 (åŠ©åŠ›è½¦)
distance_fee = distance Ã— 0.5 å…ƒ/km
time_fee = max(0, (duration_min - 30) Ã— 0.05) å…ƒ/min
```

---

## ä¸‰ã€é‡åˆ°çš„é—®é¢˜ä¸Žè§£å†³æ–¹æ¡ˆ

### 3.1 WSLè¿ç§»é—®é¢˜
**é—®é¢˜**: Cç›˜ç©ºé—´ä¸è¶³ï¼ŒWSLé»˜è®¤å®‰è£…åœ¨Cç›˜  
**è§£å†³**: ä½¿ç”¨`wsl --export/import`è¿ç§»åˆ°Eç›˜  
**å­¦ä¹ ç‚¹**: WSLçš„å¯¼å…¥å¯¼å‡ºæœºåˆ¶ã€VHDè™šæ‹Ÿç¡¬ç›˜

### 3.2 SSHè¿žæŽ¥å¤±è´¥
**é—®é¢˜**: Hadoopå¯åŠ¨æŠ¥é”™ "ssh: connect to host localhost port 22: Connection refused"  
**è§£å†³**: 
1. å®‰è£…openssh-server
2. å¯åŠ¨sshæœåŠ¡
3. é…ç½®å…å¯†ç™»å½•  
**å­¦ä¹ ç‚¹**: SSHå¯†é’¥è®¤è¯ã€authorized_keysé…ç½®

### 3.3 PythonåŒ…ç®¡ç†é™åˆ¶
**é—®é¢˜**: Ubuntu 24æ–°ç‰ˆæœ¬é™åˆ¶å…¨å±€pipå®‰è£…  
**è§£å†³**: ä½¿ç”¨`--break-system-packages`å‚æ•°  
**å­¦ä¹ ç‚¹**: PEP 668è§„èŒƒã€è™šæ‹ŸçŽ¯å¢ƒvså…¨å±€å®‰è£…çš„æƒè¡¡

### 3.4 æ–‡ä»¶è·¯å¾„è®¿é—®
**é—®é¢˜**: WSLæ— æ³•ç›´æŽ¥è®¿é—®ä¸Šä¼ çš„CSVæ–‡ä»¶  
**è§£å†³**: ä»ŽWindowsè·¯å¾„å¤åˆ¶åˆ°WSL  
**å­¦ä¹ ç‚¹**: WSLä¸ŽWindowsæ–‡ä»¶ç³»ç»Ÿäº¤äº’ï¼ˆ/mnt/d/è·¯å¾„ï¼‰

### 3.5 Cursorç¼–è¾‘å™¨é”™è¯¯
**é—®é¢˜**: `code .`å‘½ä»¤æŠ¥é”™ç¼ºå°‘minimistæ¨¡å—  
**è§£å†³**: ä½¿ç”¨å‘½ä»¤è¡Œå·¥å…·ï¼ˆnanoï¼‰æˆ–ç›´æŽ¥ä»ŽWindowsæ‰“å¼€  
**å­¦ä¹ ç‚¹**: WSLè¿œç¨‹å¼€å‘çš„å¤šç§æ–¹å¼

---

## å››ã€æŠ€æœ¯äº®ç‚¹ä¸Žåˆ›æ–°ç‚¹

### 4.1 çœŸå®žåœºæ™¯è¿˜åŽŸ
âœ… åŸºäºŽKaggleçœŸå®žæ•°æ®é›†  
âœ… åŽç››é¡¿ç‰¹åŒºå®žé™…åŒºåŸŸå¸ƒå±€  
âœ… éœ€æ±‚æ¨¡åž‹è€ƒè™‘å¤šç»´åº¦å› ç´ ï¼ˆæ—¶é—´ã€å¤©æ°”ã€å·¥ä½œæ—¥ï¼‰

### 4.2 æ•°æ®è´¨é‡ä¿è¯
âœ… 578ç§åœºæ™¯ç»„åˆçš„éœ€æ±‚æ ¡å‡†  
âœ… å¤šé‡è´¨é‡æ£€æŸ¥ï¼ˆåˆ†å¸ƒã€åˆç†æ€§ã€ä¸€è‡´æ€§ï¼‰  
âœ… å¯å¤çŽ°çš„éšæœºæ•°æŽ§åˆ¶

### 4.3 å·¥ç¨‹åŒ–å®žè·µ
âœ… æ¨¡å—åŒ–é¡¹ç›®ç»“æž„  
âœ… è‡ªåŠ¨åŒ–è„šæœ¬ï¼ˆæ•°æ®ç”Ÿæˆã€HDFSä¸Šä¼ ï¼‰  
âœ… å®Œå–„çš„æ–‡æ¡£å’Œæ³¨é‡Š

### 4.4 æŠ€æœ¯æ·±åº¦
âœ… Hadoopç”Ÿæ€ä½“ç³»ï¼ˆHDFS + YARNï¼‰  
âœ… Sparkåˆ†å¸ƒå¼è®¡ç®—  
âœ… éœ€æ±‚å»ºæ¨¡æ–¹æ³•è®ºï¼ˆPoisson/GBDTï¼‰

---

## äº”ã€åŽç»­å·¥ä½œè®¡åˆ’

### **M1 é˜¶æ®µå‰©ä½™ä»»åŠ¡ï¼ˆDay 2-3ï¼‰- 10æœˆ27-29æ—¥**

#### **Day 2: éœ€æ±‚æ¨¡åž‹æ‹Ÿåˆä¸Žåˆæ­¥åˆ†æž**

**ä»»åŠ¡1: éœ€æ±‚å¼ºåº¦å‡½æ•°Î»(t)æ‹Ÿåˆ** â­
```python
# ä½¿ç”¨Poissonå›žå½’
import statsmodels.api as sm
model = sm.GLM(y, X, family=sm.families.Poisson()).fit()

# æˆ–ä½¿ç”¨XGBoost
import xgboost as xgb
model = xgb.XGBRegressor(objective='count:poisson')
```

**è¾“å‡º**:
- å›žå½’ç³»æ•°è¡¨ï¼ˆÎ²_hour, Î²_season, Î²_weekday, Î²_weatherï¼‰
- æ‹Ÿåˆæ›²çº¿å›¾ï¼ˆé¢„æµ‹vså®žé™…ï¼‰
- æ¨¡åž‹è¯„ä¼°æŠ¥å‘Šï¼ˆRMSE, MAE, RÂ²ï¼‰

**ä»»åŠ¡2: Sparkæ•°æ®åˆ†æžè„šæœ¬**

**åˆ†æžç»´åº¦**:
1. **æ—¶é—´ç»´åº¦**
   - å°æ—¶åˆ†å¸ƒï¼šè¯†åˆ«æ—©æ™šé«˜å³°
   - å·¥ä½œæ—¥vså‘¨æœ«å¯¹æ¯”
   - æœˆåº¦/å­£åº¦è¶‹åŠ¿

2. **å¤©æ°”ç»´åº¦**
   - å¤©æ°”å¯¹éœ€æ±‚çš„å½±å“
   - æ¸©åº¦ä¸Žéª‘è¡Œé‡ç›¸å…³æ€§
   - æžç«¯å¤©æ°”åº”å¯¹

3. **ç©ºé—´ç»´åº¦**
   - åŒºåŸŸçƒ­åŠ›å›¾
   - ODçŸ©é˜µï¼ˆèµ·ç‚¹-ç»ˆç‚¹æµé‡ï¼‰
   - è·¨åŒºæµåŠ¨æ¨¡å¼

4. **ç”¨æˆ·/è½¦è¾†ç»´åº¦**
   - Top Næ´»è·ƒç”¨æˆ·
   - Top Né«˜é¢‘å•è½¦
   - ä¼šå‘˜vsæ™®é€šç”¨æˆ·å¯¹æ¯”
   - æ™®é€šè½¦vsåŠ©åŠ›è½¦ä½¿ç”¨çŽ‡

**æŠ€æœ¯å®žçŽ°**:
```python
# PySparkåˆ†æžç¤ºä¾‹
df = spark.read.csv("/bike_data/raw/orders_100k.csv", header=True)

# å°æ—¶åˆ†å¸ƒ
hourly_dist = df.groupBy("hr").count().orderBy("hr")

# åŒºåŸŸçƒ­åŠ›å›¾
zone_heatmap = df.groupBy("start_zone", "hr") \
                 .count() \
                 .pivot("hr") \
                 .sum("count")
```

**ä»»åŠ¡3: æ•°æ®å¯è§†åŒ–å¼€å‘**

**å¯è§†åŒ–ç±»åž‹**:
- æŠ˜çº¿å›¾ï¼šæ—¶é—´è¶‹åŠ¿
- æŸ±çŠ¶å›¾ï¼šåˆ†ç±»å¯¹æ¯”
- çƒ­åŠ›å›¾ï¼šæ—¶ç©ºåˆ†å¸ƒ
- é¥¼å›¾ï¼šå æ¯”åˆ†æž
- åœ°å›¾ï¼šåœ°ç†åˆ†å¸ƒ

**å·¥å…·**: Pyecharts
```python
from pyecharts import options as opts
from pyecharts.charts import Line, Bar, HeatMap, Pie

# åˆ›å»ºäº¤äº’å¼å›¾è¡¨
line = Line().add_xaxis(hours).add_yaxis("è®¢å•é‡", counts)
```

**è¾“å‡º**: 
- HTMLå¯è§†åŒ–é¡µé¢ï¼ˆanalysis_dashboard.htmlï¼‰
- å¯åµŒå…¥Flaskåº”ç”¨

---

#### **Day 3: åˆ†æžæŠ¥å‘Šä¸Žæ•°æ®éªŒè¯**

**ä»»åŠ¡1: ç”Ÿæˆåˆ†æžæŠ¥å‘Š**
- æ•°æ®è´¨é‡æŠ¥å‘Š
- æè¿°æ€§ç»Ÿè®¡æŠ¥å‘Š
- éœ€æ±‚æ¨¡åž‹æ ¡å‡†æŠ¥å‘Š
- å¯è§†åŒ–å›¾è¡¨é›†

**ä»»åŠ¡2: æ¨¡åž‹éªŒè¯ä¸Žè°ƒä¼˜**
- äº¤å‰éªŒè¯
- è¶…å‚æ•°è°ƒä¼˜
- é²æ£’æ€§æµ‹è¯•ï¼ˆæžç«¯åœºæ™¯ï¼‰

**ä»»åŠ¡3: å‡†å¤‡M2é˜¶æ®µåŸºç¡€**
- å¯¼å‡ºÎ»(t)å‚æ•°æ–‡ä»¶
- ç¼–å†™éœ€æ±‚é‡‡æ ·å‡½æ•°
- è®¾è®¡è°ƒåº¦æ¨¡æ‹Ÿå™¨æŽ¥å£

**è¾“å‡º**: 
- åˆ†æžé¡µé¢1.0ï¼ˆHTML Dashboardï¼‰
- éœ€æ±‚æ¨¡åž‹å‚æ•°æ–‡ä»¶ï¼ˆlambda_params.pklï¼‰
- åˆ†æžæŠ¥å‘Šæ–‡æ¡£ï¼ˆanalysis_report.mdï¼‰

---

### **M2 é˜¶æ®µï¼šè°ƒåº¦æ¨¡æ‹Ÿå™¨ï¼ˆDay 4-6ï¼‰- 10æœˆ30æ—¥-11æœˆ1æ—¥**

#### **æ ¸å¿ƒä»»åŠ¡**

**ä»»åŠ¡1: GymçŽ¯å¢ƒæ­å»º**
```python
import gymnasium as gym

class BikeRebalancingEnv(gym.Env):
    def __init__(self, config):
        self.num_zones = 6
        self.time_horizon = 24 * 7  # ä¸€å‘¨
        # çŠ¶æ€ç©ºé—´ï¼šå„åŒºåº“å­˜ + æ—¶é—´ä¸Šä¸‹æ–‡
        # åŠ¨ä½œç©ºé—´ï¼šè°ƒåº¦å†³ç­–çŸ©é˜µ
        
    def reset(self):
        # åˆå§‹åŒ–åº“å­˜ã€æ—¶é—´
        
    def step(self, action):
        # æ‰§è¡Œè°ƒåº¦ã€éœ€æ±‚é‡‡æ ·ã€æ›´æ–°åº“å­˜
        # è®¡ç®—å¥–åŠ±ï¼šrevenue - penalty - cost
```

**çŠ¶æ€è®¾è®¡**:
```python
state = {
    'inventory': [B_1, B_2, ..., B_6],  # å„åŒºåº“å­˜
    'hour': h,                           # å½“å‰å°æ—¶
    'weekday': w,                        # æ˜ŸæœŸ
    'season': s,                         # å­£èŠ‚
    'weather': k                         # å¤©æ°”
}
```

**åŠ¨ä½œè®¾è®¡** (ç®€åŒ–ç‰ˆ-å¤œé—´è°ƒåº¦):
```python
action = [
    [0, 5, 0, 0, 0, 0],   # ä»ŽåŒºåŸŸ1è°ƒ5è¾†åˆ°åŒºåŸŸ2
    [0, 0, 0, 3, 0, 0],   # ä»ŽåŒºåŸŸ2è°ƒ3è¾†åˆ°åŒºåŸŸ4
    ...
]
```

**å¥–åŠ±å‡½æ•°**:
```python
reward = (
    revenue_per_trip Ã— sum(served_demands) 
    - penalty_per_unmet Ã— sum(unmet_demands)
    - sum(distance_cost Ã— quantities)
)
```

**ä»»åŠ¡2: åŸºçº¿ç­–ç•¥å®žçŽ°**

**Zero-Action**:
```python
def zero_action(state):
    return np.zeros((num_zones, num_zones))
```

**Proportional Refill**:
```python
def proportional_refill(state, historical_avg):
    target_inventory = historical_avg * total_bikes
    action = allocate_proportionally(state['inventory'], target_inventory)
    return action
```

**Min-Cost Flow** (ç®€åŒ–è´ªå¿ƒ):
```python
def min_cost_flow(state):
    surplus_zones = [z for z in zones if inventory[z] > threshold]
    deficit_zones = [z for z in zones if inventory[z] < threshold]
    # è´ªå¿ƒåŒ¹é…æœ€çŸ­è·¯å¾„
```

**ä»»åŠ¡3: æ¨¡æ‹Ÿå™¨æµ‹è¯•ä¸Žè¯„ä¼°**
- å•å…ƒæµ‹è¯•ï¼šåº“å­˜å®ˆæ’ã€æˆæœ¬è®¡ç®—
- åŸºçº¿å¯¹æ¯”ï¼šZero vs Proportional vs MinCost
- è¾“å‡ºè¯„ä¼°CSVå’Œå¯¹æ¯”å›¾è¡¨

**è¾“å‡º**:
- GymçŽ¯å¢ƒä»£ç ï¼ˆbike_env.pyï¼‰
- åŸºçº¿ç­–ç•¥ä»£ç ï¼ˆbaseline_policies.pyï¼‰
- è¯„ä¼°è„šæœ¬ï¼ˆevaluate.pyï¼‰
- å¯¹æ¯”æŠ¥å‘Šï¼ˆbaseline_comparison.htmlï¼‰

---

### **M3 é˜¶æ®µï¼šå¼ºåŒ–å­¦ä¹ è®­ç»ƒï¼ˆDay 7-9ï¼‰- 11æœˆ2-4æ—¥**

#### **æ ¸å¿ƒä»»åŠ¡**

**ä»»åŠ¡1: PPOç®—æ³•è®­ç»ƒ**
```python
from stable_baselines3 import PPO

model = PPO(
    "MlpPolicy",
    env,
    learning_rate=3e-4,
    n_steps=2048,
    batch_size=64,
    n_epochs=10,
    gamma=0.99,
    verbose=1
)

model.learn(total_timesteps=100000)
model.save("ppo_bike_rebalancing")
```

**è¶…å‚æ•°è°ƒä¼˜**:
- learning_rate: [1e-4, 3e-4, 1e-3]
- n_steps: [1024, 2048, 4096]
- gamma: [0.95, 0.99, 0.999]

**ä»»åŠ¡2: è®­ç»ƒç›‘æŽ§ä¸Žå¯è§†åŒ–**
```python
from stable_baselines3.common.callbacks import EvalCallback

eval_callback = EvalCallback(
    eval_env,
    best_model_save_path='./logs/',
    log_path='./logs/',
    eval_freq=1000
)
```

**ç›‘æŽ§æŒ‡æ ‡**:
- Episode rewardæ›²çº¿
- æœåŠ¡çŽ‡è¶‹åŠ¿
- ç¼ºå£é‡å˜åŒ–
- è°ƒåº¦æˆæœ¬

**ä»»åŠ¡3: ç­–ç•¥å¯¹æ¯”è¯„ä¼°**
- RL vs å¯å‘å¼åŸºçº¿
- ä¸åŒå¤©æ°”/å­£èŠ‚/é¢„ç®—åœºæ™¯
- é²æ£’æ€§æµ‹è¯•ï¼ˆéšæœºç§å­ï¼‰

**è¾“å‡º**:
- è®­ç»ƒå¥½çš„PPOæ¨¡åž‹ï¼ˆppo_model.zipï¼‰
- è®­ç»ƒæ›²çº¿å›¾ï¼ˆtraining_curves.pngï¼‰
- ç­–ç•¥å¯¹æ¯”æŠ¥å‘Šï¼ˆrl_vs_baseline.htmlï¼‰
- è¯„ä¼°æŒ‡æ ‡è¡¨ï¼ˆevaluation_metrics.csvï¼‰

---

### **M4 é˜¶æ®µï¼šå¹³å°é›†æˆä¸Žæ¼”ç¤ºï¼ˆDay 10-12ï¼‰- 11æœˆ5-7æ—¥**

#### **æ ¸å¿ƒä»»åŠ¡**

**ä»»åŠ¡1: Flask Webåº”ç”¨å¼€å‘**
```python
from flask import Flask, render_template, request

app = Flask(__name__)

@app.route('/')
def index():
    return render_template('dashboard.html')

@app.route('/analysis')
def analysis():
    # å±•ç¤ºåˆ†æžç»“æžœ
    
@app.route('/simulation', methods=['POST'])
def simulation():
    # è¿è¡Œä»¿çœŸï¼Œè¿”å›žç»“æžœ
    config = request.json
    results = run_simulation(config)
    return jsonify(results)
```

**é¡µé¢è®¾è®¡**:
1. **é¦–é¡µ**: é¡¹ç›®æ¦‚è§ˆ
2. **åˆ†æžé¡µ**: 
   - æ—¶é—´è¶‹åŠ¿å›¾
   - å¤©æ°”å½±å“å›¾
   - åŒºåŸŸçƒ­åŠ›å›¾
   - Top Næ¦œå•
3. **ä»¿çœŸé¡µ**:
   - åœºæ™¯é…ç½®é¢æ¿
   - ç­–ç•¥é€‰æ‹©å™¨
   - å®žæ—¶æŒ‡æ ‡å±•ç¤º
   - å¯¹æ¯”å›¾è¡¨
4. **What-ifé¡µ**:
   - å‚æ•°è°ƒèŠ‚ï¼ˆå¤©æ°”ã€é¢„ç®—ã€åŒºåŸŸæ•°ï¼‰
   - ä¸€é”®é‡è·‘ä»¿çœŸ
   - ç»“æžœå¯¹æ¯”

**ä»»åŠ¡2: å‰ç«¯å¯è§†åŒ–ä¼˜åŒ–**
- å“åº”å¼å¸ƒå±€
- äº¤äº’å¼å›¾è¡¨ï¼ˆPyechartsï¼‰
- åŠ¨ç”»æ•ˆæžœ
- å¯¼å‡ºåŠŸèƒ½ï¼ˆPDF/PNGï¼‰

**ä»»åŠ¡3: æ–‡æ¡£ä¸ŽPPTå‡†å¤‡**

**æ–‡æ¡£å†…å®¹**:
- é¡¹ç›®èƒŒæ™¯ä¸Žæ„ä¹‰
- æŠ€æœ¯æž¶æž„ä¸Žå®žçŽ°
- æ•°æ®åˆ†æžç»“æžœ
- æ¨¡åž‹æ€§èƒ½è¯„ä¼°
- ç»“è®ºä¸Žå±•æœ›

**PPTç»“æž„**:
1. å°é¢ï¼šé¡¹ç›®æ ‡é¢˜ã€å›¢é˜Ÿ
2. èƒŒæ™¯ï¼šå…±äº«å•è½¦è¡Œä¸šçŽ°çŠ¶
3. ç›®æ ‡ï¼šè¦è§£å†³çš„é—®é¢˜
4. æ–¹æ³•ï¼šæŠ€æœ¯è·¯çº¿å›¾
5. æ•°æ®ï¼šæ•°æ®æ¥æºä¸Žç”Ÿæˆ
6. åˆ†æžï¼šå¤šç»´åº¦æ•°æ®æ´žå¯Ÿ
7. å»ºæ¨¡ï¼šéœ€æ±‚é¢„æµ‹æ¨¡åž‹
8. è°ƒåº¦ï¼šGymçŽ¯å¢ƒä¸Žç­–ç•¥
9. è®­ç»ƒï¼šå¼ºåŒ–å­¦ä¹ è¿‡ç¨‹
10. ç»“æžœï¼šæ€§èƒ½å¯¹æ¯”ä¸Žè¯„ä¼°
11. æ¼”ç¤ºï¼šLive Demo
12. æ€»ç»“ï¼šæˆæžœä¸Žæœªæ¥å·¥ä½œ

**è¾“å‡º**:
- Flaskåº”ç”¨ï¼ˆapp.py + templates/ï¼‰
- å®Œæ•´æ–‡æ¡£ï¼ˆproject_report.mdï¼‰
- ç­”è¾©PPTï¼ˆpresentation.pptxï¼‰
- æ¼”ç¤ºè§†é¢‘ï¼ˆdemo.mp4ï¼Œå¯é€‰ï¼‰

---

## å…­ã€æŠ€æœ¯å­¦ä¹ è·¯çº¿å›¾

### **å·²æŽŒæ¡æŠ€èƒ½** âœ…
- [x] Linuxå‘½ä»¤è¡Œæ“ä½œ
- [x] WSLçŽ¯å¢ƒé…ç½®
- [x] Hadoop HDFSåŸºç¡€
- [x] Sparkå®‰è£…é…ç½®
- [x] Pythonæ•°æ®å¤„ç†ï¼ˆPandas/NumPyï¼‰
- [x] æ¨¡æ‹Ÿæ•°æ®ç”Ÿæˆï¼ˆFakerï¼‰

### **æœ¬å‘¨éœ€æŽŒæ¡** ðŸ“š
- [ ] PySpark DataFrame API
- [ ] éœ€æ±‚é¢„æµ‹æ¨¡åž‹ï¼ˆPoissonå›žå½’/XGBoostï¼‰
- [ ] Pyechartså¯è§†åŒ–
- [ ] Gymnasium (OpenAI Gym)çŽ¯å¢ƒå¼€å‘
- [ ] å¼ºåŒ–å­¦ä¹ åŸºç¡€ï¼ˆPPOç®—æ³•ï¼‰
- [ ] Flask Webå¼€å‘

### **è¿›é˜¶æŠ€èƒ½** ðŸš€
- [ ] åˆ†å¸ƒå¼è®¡ç®—åŽŸç†
- [ ] æ—¶é—´åºåˆ—é¢„æµ‹
- [ ] æ·±åº¦å¼ºåŒ–å­¦ä¹ ï¼ˆDQN/A3Cï¼‰
- [ ] å®¹å™¨åŒ–éƒ¨ç½²ï¼ˆDockerï¼‰
- [ ] å‰ç«¯æ¡†æž¶ï¼ˆVue.js/Reactï¼‰

---

## ä¸ƒã€é£Žé™©é¢„è­¦ä¸Žåº”å¯¹

### **é£Žé™©1: æ—¶é—´ç´§å¼ **
**è¡¨çŽ°**: 12å¤©å®Œæˆä»Žæ•°æ®åˆ°æ¼”ç¤ºçš„å®Œæ•´æµç¨‹  
**åº”å¯¹**:
- ä¼˜å…ˆä¿è¯æ ¸å¿ƒåŠŸèƒ½ï¼ˆåˆ†æž+æ¨¡æ‹Ÿ+è®­ç»ƒï¼‰
- ç®€åŒ–å¯è§†åŒ–ï¼ˆç”¨Pyechartsé»˜è®¤ä¸»é¢˜ï¼‰
- å¤ç”¨å¼€æºä»£ç ï¼ˆstable-baselines3ï¼‰
- å¹¶è¡Œå¼€å‘ï¼ˆåˆ†æžå’Œæ¨¡æ‹Ÿå™¨å¯åŒæ­¥è¿›è¡Œï¼‰

### **é£Žé™©2: æ¨¡åž‹æ‹Ÿåˆä¸ä½³**
**è¡¨çŽ°**: Î»(t)é¢„æµ‹è¯¯å·®å¤§ï¼Œå½±å“æ¨¡æ‹Ÿå¯ä¿¡åº¦  
**åº”å¯¹**:
- å¤šå°è¯•å‡ ç§æ¨¡åž‹ï¼ˆPoisson/GBDT/æ··åˆï¼‰
- å¢žåŠ ç‰¹å¾å·¥ç¨‹ï¼ˆèŠ‚å‡æ—¥æ ‡è¯†ã€æœˆä»½ç­‰ï¼‰
- é€‚å½“å¹³æ»‘å¼‚å¸¸å€¼

### **é£Žé™©3: RLè®­ç»ƒä¸ç¨³å®š**
**è¡¨çŽ°**: rewardæ³¢åŠ¨å¤§ï¼Œç­–ç•¥ä¸æ”¶æ•›  
**åº”å¯¹**:
- é™ä½ŽçŽ¯å¢ƒå¤æ‚åº¦ï¼ˆå‡å°‘åŒºåŸŸæ•°/æ—¶é—´è·¨åº¦ï¼‰
- å½’ä¸€åŒ–å¥–åŠ±å’ŒçŠ¶æ€
- è°ƒæ•´è¶…å‚æ•°ï¼ˆlearning rateã€gammaï¼‰
- å¢žåŠ è®­ç»ƒæ—¶é•¿

### **é£Žé™©4: è®¡ç®—èµ„æºä¸è¶³**
**è¡¨çŽ°**: è®­ç»ƒç¼“æ…¢ï¼Œå†…å­˜æº¢å‡º  
**åº”å¯¹**:
- ä½¿ç”¨å°è§„æ¨¡çŽ¯å¢ƒï¼ˆK=6, T=7Ã—24ï¼‰
- æ‰¹é‡ç”Ÿæˆæ•°æ®è€Œéžå…¨éƒ¨åŠ è½½
- åˆ©ç”¨WSLä¸ŽWindowså…±äº«èµ„æº
- å¿…è¦æ—¶ä½¿ç”¨äº‘æœåŠ¡å™¨ï¼ˆAWS/é˜¿é‡Œäº‘å­¦ç”Ÿæœºï¼‰

---

## å…«ã€å‚è€ƒèµ„æ–™ä¸Žå­¦ä¹ èµ„æº

### **å®˜æ–¹æ–‡æ¡£**
- [Hadoopå®˜æ–¹æ–‡æ¡£](https://hadoop.apache.org/docs/)
- [Sparkå®˜æ–¹æ–‡æ¡£](https://spark.apache.org/docs/latest/)
- [PySpark APIæ–‡æ¡£](https://spark.apache.org/docs/latest/api/python/)
- [Gymnasiumæ–‡æ¡£](https://gymnasium.farama.org/)
- [Stable-Baselines3æ–‡æ¡£](https://stable-baselines3.readthedocs.io/)

### **æ•™ç¨‹èµ„æº**
- PySparkæ•°æ®åˆ†æžæ•™ç¨‹
- Pyechartså¯è§†åŒ–ç¤ºä¾‹
- å¼ºåŒ–å­¦ä¹ å…¥é—¨ï¼ˆSpinning Up in RLï¼‰
- Flaskå¿«é€Ÿå¼€å‘æŒ‡å—

### **æ•°æ®é›†æ¥æº**
- [Kaggle Bike Sharing Dataset](https://www.kaggle.com/c/bike-sharing-demand)
- Capital Bikeshareå¼€æ”¾æ•°æ®

---

## ä¹ã€é¡¹ç›®äº¤ä»˜ç‰©æ£€æŸ¥æ¸…å•

### **M1é˜¶æ®µ** (10-27 ~ 10-29)
- [x] 10ä¸‡æ¡è®¢å•æ•°æ®
- [x] é¡¹ç›®ç›®å½•ç»“æž„
- [x] æ•°æ®ç”Ÿæˆè„šæœ¬
- [ ] éœ€æ±‚æ¨¡åž‹Î»(t)ï¼ˆDay 2ï¼‰
- [ ] åˆ†æžé¡µé¢1.0ï¼ˆDay 3ï¼‰

### **M2é˜¶æ®µ** (10-30 ~ 11-01)
- [ ] Gymè°ƒåº¦çŽ¯å¢ƒ
- [ ] 3ç§åŸºçº¿ç­–ç•¥
- [ ] åŸºçº¿å¯¹æ¯”æŠ¥å‘Š

### **M3é˜¶æ®µ** (11-02 ~ 11-04)
- [ ] PPOè®­ç»ƒè„šæœ¬
- [ ] è®­ç»ƒå¥½çš„æ¨¡åž‹
- [ ] RL vsåŸºçº¿å¯¹æ¯”

### **M4é˜¶æ®µ** (11-05 ~ 11-07)
- [ ] Flaskæ¼”ç¤ºåº”ç”¨
- [ ] What-ifä»¿çœŸé¡µé¢
- [ ] é¡¹ç›®æ–‡æ¡£
- [ ] ç­”è¾©PPT

---

## åã€Day 1 å¿ƒå¾—ä½“ä¼š

### **æŠ€æœ¯æ”¶èŽ·**
1. æŽŒæ¡äº†WSLçŽ¯å¢ƒçš„é…ç½®ä¸Žè¿ç§»
2. ç†è§£äº†Hadoop/Sparkçš„å®‰è£…ä¸Žå¯åŠ¨æµç¨‹
3. å­¦ä¼šäº†åŸºäºŽçœŸå®žæ•°æ®æž„å»ºæ¨¡æ‹Ÿæ•°æ®é›†
4. ä½“ä¼šåˆ°å¤§æ•°æ®é¡¹ç›®çš„å®Œæ•´å·¥ç¨‹æµç¨‹

### **é‡åˆ°çš„æŒ‘æˆ˜**
1. WSLä¸ŽWindowsæ–‡ä»¶ç³»ç»Ÿäº¤äº’ç†è§£
2. SSHæœåŠ¡é…ç½®é—®é¢˜æŽ’æŸ¥
3. PythonåŒ…ç®¡ç†ç­–ç•¥é€‰æ‹©
4. æ•°æ®ç”Ÿæˆè„šæœ¬çš„è·¯å¾„å¤„ç†

### **æ”¹è¿›æ–¹å‘**
1. æå‰è§„åˆ’å¥½æ–‡ä»¶è·¯å¾„ç»“æž„
2. ç†Ÿæ‚‰å¸¸ç”¨Linuxå‘½ä»¤åŠ å¿«æ“ä½œ
3. å­¦ä¹ ä½¿ç”¨VSCode Remote-WSL
4. å‡†å¤‡å¥½æ‰€æœ‰ä¾èµ–åŒ…çš„ç¦»çº¿å®‰è£…æ–¹æ¡ˆ

---

## åä¸€ã€æ€»ç»“ä¸Žå±•æœ›

### **Day 1æˆå°±** ðŸŽ‰
- âœ… å®Œæ•´çš„å¼€å‘çŽ¯å¢ƒæ­å»º
- âœ… 10ä¸‡æ¡é«˜è´¨é‡æ•°æ®ç”Ÿæˆ
- âœ… åŸºäºŽçœŸå®žéœ€æ±‚æ¨¡åž‹æ ¡å‡†
- âœ… æ¸…æ™°çš„é¡¹ç›®ç»“æž„è§„åˆ’

### **æŽ¥ä¸‹æ¥çš„é‡ç‚¹**
1. **Day 2**: éœ€æ±‚æ¨¡åž‹æ‹Ÿåˆï¼ŒéªŒè¯Î»(t)å‡†ç¡®æ€§
2. **Day 3**: å¤šç»´åº¦æ•°æ®åˆ†æžï¼Œå¯è§†åŒ–å±•ç¤º
3. **Day 4-6**: GymçŽ¯å¢ƒå¼€å‘ï¼ŒåŸºçº¿ç­–ç•¥å¯¹æ¯”
4. **Day 7-9**: å¼ºåŒ–å­¦ä¹ è®­ç»ƒï¼Œæ€§èƒ½ä¼˜åŒ–
5. **Day 10-12**: å¹³å°é›†æˆï¼Œæ–‡æ¡£ç­”è¾©å‡†å¤‡

### **é¡¹ç›®æ„¿æ™¯**
é€šè¿‡æœ¬é¡¹ç›®ï¼Œä¸ä»…è¦å®Œæˆå­¦ä¸šè¦æ±‚ï¼Œæ›´è¦ï¼š
- æŽŒæ¡å¤§æ•°æ®æŠ€æœ¯æ ˆçš„å®žé™…åº”ç”¨
- ç†è§£å¼ºåŒ–å­¦ä¹ åœ¨å®žé™…é—®é¢˜ä¸­çš„è½åœ°
- åŸ¹å…»ç«¯åˆ°ç«¯é¡¹ç›®å¼€å‘èƒ½åŠ›
- ç§¯ç´¯å¯å±•ç¤ºçš„ä½œå“é›†

---

**é¡¹ç›®è¿›åº¦**: ç¬¬1å¤©/12å¤©ï¼ˆ8.3%ï¼‰  
**é¢„è®¡å®Œæˆæ—¶é—´**: 2025-11-07  
**å½“å‰çŠ¶æ€**: âœ… æŒ‰è®¡åˆ’æŽ¨è¿›

**ä¸‹ä¸€æ­¥è¡ŒåŠ¨**: 
æ˜Žå¤©ï¼ˆ10-27ï¼‰å¼€å§‹éœ€æ±‚æ¨¡åž‹æ‹Ÿåˆä¸ŽSparkåˆ†æžå¼€å‘

---

*æŠ¥å‘Šç”Ÿæˆæ—¶é—´: 2025-10-26 13:30*  
*é¡¹ç›®è´Ÿè´£äºº: renr*  
*æŠ€æœ¯æ”¯æŒ: Claude (Anthropic)*
